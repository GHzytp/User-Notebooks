{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bef70a7",
   "metadata": {},
   "source": [
    "## This notebook does the follwoing:\n",
    "- Loads the outcome of segmentation from VADF_series_SED notebook\n",
    "- Applies a user-defined size threshold to the segmentation and separates them into spatially distinct domains \n",
    "- Generates a series sum difraction signal and their azimuthal integrations with the applied masks defined above\n",
    "- Saves the images / signal outputs in a sub-dir **Segment_sums** to the path where the data is located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2b7af",
   "metadata": {},
   "source": [
    "```yaml\n",
    "global_segmentation_path: \n",
    "    value: 'None'\n",
    "    explanation: 'Path to the hspy file with the desired segmentation. Leave to None if there is only one outcome of the VADF_Series_SED notebook'\n",
    "global_use_binned_data:\n",
    "    value: 'True'\n",
    "    explanation: 'For the thick samples we may opt to bin the data by 2 as the outcome of the Apply_Cal_to_SED_data notebook, if so set to True'\n",
    "global_DBSCAN_min_threshold: \n",
    "    value: '5'\n",
    "    explanation: 'Min size of the segmentation.'\n",
    "global_DBSCAN_eps:\n",
    "    value: '2.8'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Testing\n",
    "# # # dataset name\n",
    "# data_label = 'pct0_FIB/20230126_133423'\n",
    "# # data_label = 'pct0_FIB/20230126_131428'\n",
    "# # notebook name\n",
    "# # notebook = 'Apply_Cal_to_SED_data'\n",
    "# global_DBSCAN_min_threshold = '5'\n",
    "# global_segmentation_path = 'None'\n",
    "# global_use_binned_data = 'True'\n",
    "# global_DBSCAN_eps = '2.8'\n",
    "# # global_cal_json_path = '/dls/e02/data/2023/mg31973-1/processing/Merlin/au_xgrating/calibrations_diff_20230125_093528.json'\n",
    "# # global_crop_window_size = '0.01'\n",
    "\n",
    "# BEAMLINE = 'e02'\n",
    "# YEAR = '2023'\n",
    "# VISIT = 'mg31973-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperspy.api as hs\n",
    "import os\n",
    "import pyxem as pxm\n",
    "import py4DSTEM\n",
    "import logging\n",
    "from sklearn.cluster import DBSCAN\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec68ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/dls/{BEAMLINE}/data/{YEAR}/{VISIT}/processing/Merlin/'\n",
    "timestamp = data_label.split('/')[-1]\n",
    "ibf_path = f'{path}/{data_label}/{timestamp}_ibf.hspy'\n",
    "meta_path = f'{path}/{data_label}/{timestamp}.hdf'\n",
    "full_path = f'{path}/{data_label}/{timestamp}_data.hdf5'\n",
    "\n",
    "if global_use_binned_data == 'True':\n",
    "    d = hs.load(f'{path}/{data_label}/{timestamp}_calibrated_data_bin2.hspy', lazy=True)\n",
    "else:\n",
    "    d = hs.load(f'{path}/{data_label}/{timestamp}_calibrated_data.hspy', lazy=True)\n",
    "\n",
    "# Check how many segmentations outcomes are there in the dataset\n",
    "segment_path = glob.glob(f'{path}/{data_label}/vadf_series_sed.*')\n",
    "\n",
    "if len(segment_path) > 1:\n",
    "    if global_segmentation_path == 'None':\n",
    "        print('Multiple segmentations results found. We are using one of the outcomes. You can provide the path to your favourite one as an input parameter!')\n",
    "        d_seg = hs.load(f'{segment_path[-1]}/vadf_series_sed/segmentation_based_on_max_ADF_signal.hspy')\n",
    "    else:\n",
    "        d_seg = hs.load(global_segmentation_path)\n",
    "else:\n",
    "    d_seg = hs.load(f'{segment_path[0]}/vadf_series_sed/segmentation_based_on_max_ADF_signal.hspy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ae4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb962c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_seg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'{path}/{data_label}/Segment_sums'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f842d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.data.shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724837a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eps_val = float(global_DBSCAN_eps)\n",
    "min_sample = int(global_DBSCAN_min_threshold)\n",
    "\n",
    "\n",
    "# masking the BF disc\n",
    "bf_mask = np.ones(d.data.shape[2:])\n",
    "bf_mask[515//2 - 30:515//2 + 30, 515//2 - 30:515//2 + 30] = 0\n",
    "# plt.figure()\n",
    "# plt.imshow(bf_mask)\n",
    "\n",
    "for ind in np.arange(np.max(d_seg.data)):\n",
    "    mask = d_seg.data == int(ind)\n",
    "    mask_ = mask.astype('int')\n",
    "    \n",
    "    # separating into individual domains\n",
    "    _coords = np.asarray(np.where(mask_ ==1)).T\n",
    "    individual_reg = np.zeros_like(mask_)\n",
    "    individual_reg[np.where(mask_ ==1)] = DBSCAN(eps_val,min_samples = min_sample).fit_predict(_coords)+1\n",
    "    \n",
    "    # save the outcome of DBSCAN\n",
    "    plt.figure()\n",
    "    plt.imshow(individual_reg, cmap = 'turbo')\n",
    "    plt.savefig(f'{save_path}/label_{int(ind)}_individual_domains.jpg')\n",
    "    \n",
    "    # loop through these domains \n",
    "    \n",
    "    for clust_ind in np.arange(np.max(individual_reg)):\n",
    "        mask_cluster = np.where(individual_reg==clust_ind, 1,0)\n",
    "        mask_cluster = hs.signals.Signal2D(mask_cluster)\n",
    "        d_mask = d * mask_cluster.T\n",
    "        d_mask_sum = d_mask.sum()\n",
    "        # computing sum signal over masked region\n",
    "        d_mask_sum.compute()\n",
    "        # radial integration\n",
    "        d_int = d_mask_sum.radial_average()\n",
    "        \n",
    "        d_int.axes_manager[0].units = d_mask_sum.axes_manager[0].units\n",
    "        d_int.axes_manager[0].scale = d_mask_sum.axes_manager[0].scale\n",
    "        d_int.axes_manager[0].name = 'Scattering Angle'\n",
    "        \n",
    "        x_axis_ticks = d_int.axes_manager[0].scale * np.arange(d_int.data.shape[0])\n",
    "        \n",
    "        \n",
    "        fig, axs = plt.subplots(1,3, figsize=(9,3))\n",
    "        axs[0].imshow(mask_cluster.data, cmap = 'binary')\n",
    "        axs[0].set_xticks([])\n",
    "        axs[0].set_yticks([])\n",
    "        axs[0].set_title('mask')\n",
    "        axs[1].imshow(d_mask_sum.data, vmax = 0.1 * np.max(d_mask_sum.data * bf_mask), cmap='inferno')\n",
    "        axs[1].set_xticks([])\n",
    "        axs[1].set_yticks([])\n",
    "        axs[1].set_title('sum signal')\n",
    "        axs[2].plot(x_axis_ticks[30:], d_int.isig[30:].data)\n",
    "        axs[2].set(xlabel=f'Scattering Angle {d_mask_sum.axes_manager[0].units}')\n",
    "        axs[2].set(yticks = [])\n",
    "        axs[2].set_title('radial average')\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f'{save_path}/label_{int(ind)}_cluster_ind_{clust_ind}.jpg');\n",
    "        \n",
    "        d_mask_sum.save(f'{save_path}/label_{int(ind)}_cluster_ind_{clust_ind}_sum_diff.hspy', overwrite=True)\n",
    "        mask_cluster.save(f'{save_path}/label_{int(ind)}_cluster_ind_{clust_ind}_mask.hspy', overwrite=True)\n",
    "        \n",
    "        del(d_mask_sum)\n",
    "        gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.10-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
