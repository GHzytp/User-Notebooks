{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58dd9a0-58ac-4bca-8fd0-483b18bdfa7f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this notebook one can:\n",
    "- load a notebook's settings as a dictionary\n",
    "- change it \n",
    "- save it as a new notebook \n",
    "- submit it as an array job to SLURM cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd346c1-bdbf-4f9b-84ca-9021e632d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/dls_sw/e02/software/epsic_tools')\n",
    "import epsic_tools.api as ep\n",
    "import pprint\n",
    "import re\n",
    "import subprocess\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import time\n",
    "\n",
    "year = '2024'\n",
    "session = 'mg37402-1'\n",
    "sub_folder = 'FAPI_DMF_DMSO_MACl'\n",
    "au_calib_folder = 'Au_xgrating'\n",
    "au_calib_path = '/dls/e02/data/' + year + '/' + session + '/processing/Merlin/' + au_calib_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06978039-4b67-4ae2-a1b7-be2a9fa173ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "current = time.strftime(\"%s%s%s_%s%s%s\"%(time.gmtime()[0], \n",
    "                               time.gmtime()[1], \n",
    "                               time.gmtime()[2],\n",
    "                              time.gmtime()[3],\n",
    "                              time.gmtime()[4],\n",
    "                              time.gmtime()[5]))\n",
    "\n",
    "starting_notebook_path = os.getcwd() #'/dls/science/groups/e02/Sample_data/Test_data_ePSIC_User_notebooks/scripts_folder'\n",
    "starting_notebook_name = 'template_BraggAnalysis-submit'\n",
    "nb = ep.notebook_utils.NotebookHelper(starting_notebook_path, starting_notebook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eba8ff-6918-41fa-8159-0d6d4d7fa380",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_settings = nb.get_settings(1) # settings should be cell index 1\n",
    "old_settings = old_settings.split(' ')\n",
    "old_keys = [i.split('=')[0] for i in old_settings]\n",
    "old_vals = [i.split('=')[1] for i in old_settings]\n",
    "old_dict = dict(zip(old_keys, old_vals))\n",
    "pprint.pprint(old_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6ccd4-64d0-42c1-b48c-c51f4180cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_hdf5_files(root_dir):\n",
    "#     hdf5_files = []\n",
    "#     # Loop through each subdirectory in the root directory\n",
    "#     for subfolder in os.listdir(root_dir):\n",
    "#         # Check if the subfolder matches the 'SPXX' pattern\n",
    "#         if subfolder.startswith(\"Li_metal\"):\n",
    "#             spxx_path = os.path.join(root_dir, subfolder)\n",
    "#             # Loop through each dataset subfolder inside the SPXX directory\n",
    "#             for dataset_subfolder in os.listdir(spxx_path):\n",
    "#                 dataset_path = os.path.join(spxx_path, dataset_subfolder)\n",
    "#                 # Check for .hdf5 files in the dataset subfolder\n",
    "#                 for file in os.listdir(dataset_path):\n",
    "#                     if file.endswith('.hdf5'):\n",
    "#                         # Append the full path of the .hdf5 file\n",
    "#                         hdf5_files.append(os.path.join(dataset_path, file))\n",
    "#     return hdf5_files\n",
    "\n",
    "# Specify the root directory for the Merlin folders\n",
    "merlin_root = '/dls/e02/data/' + year + '/' + session + '/processing/Merlin/' + sub_folder\n",
    "#'/dls/e02/data/2024/mg37302-1/processing/Merlin'\n",
    "# Get all .hdf5 files under the specified directory\n",
    "hdf5_file_paths = data_files = glob.glob(merlin_root+ '/*/*.hdf5')\n",
    "#find_hdf5_files(merlin_root)\n",
    "\n",
    "# Output the paths\n",
    "hdf5_file_paths.sort()\n",
    "print(len(hdf5_file_paths))\n",
    "print(*hdf5_file_paths, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f19541-a7e5-4e0a-8f03-d26206a53467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some changes in new setting\n",
    "# log files from the cluster jobs and the bash script will be saved here:\n",
    "code_path = merlin_root + '/cluster_logs'\n",
    "if not os.path.exists(code_path):\n",
    "    os.mkdir(code_path)\n",
    "concurrent_jobs = 2 #Integer number of concurrent jobs to run in the array\n",
    "\n",
    "new_notebook_paths_list = []\n",
    "for file in hdf5_file_paths:\n",
    "    # update the settings\n",
    "    new_setting = old_dict.copy()\n",
    "    new_setting['crop_q'] = ''\n",
    "    new_setting['raw_data_path'] = file\n",
    "    new_setting['save_path_name'] = 'cluster_processed'\n",
    "    new_setting['Au_calib_path'] = au_calib_path\n",
    "    #pprint.pprint(new_setting)\n",
    "\n",
    "    save_path = os.path.join(os.path.dirname(file), new_setting['save_path_name'])\n",
    "    #print(save_path)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    new_notebook_path = os.path.join(save_path, 'submitted_notebook.ipynb')\n",
    "    nb.set_settings(new_setting, new_notebook_path)\n",
    "    print(f'new notebook path: {new_notebook_path}')\n",
    "    new_notebook_paths_list.append(new_notebook_path)\n",
    "\n",
    "note_book_path_file = os.path.join(code_path, 'notebook_list.txt')\n",
    "with open (note_book_path_file, 'w') as f:\n",
    "    f.write(\n",
    "        '\\n'.join(new_notebook_paths_list)\n",
    "    )\n",
    "\n",
    "bash_script_path = os.path.join(code_path, 'cluster_submit.sh')\n",
    "with open (bash_script_path, 'w') as f:\n",
    "    f.write('''#!/usr/bin/env bash\n",
    "#SBATCH --partition cs04r\n",
    "#SBATCH --job-name epsic_notebook\n",
    "#SBATCH --time 05:00:00\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --gpus-per-node 0\n",
    "#SBATCH --tasks-per-node 1\n",
    "#SBATCH --mem 128G\n",
    "'''\n",
    "f\"#SBATCH --array=0-{len(new_notebook_paths_list)-1}%{int(concurrent_jobs)}\\n\"\n",
    "f\"#SBATCH --error={code_path}{os.sep}logs_{current}{os.sep}error_%j.out\\n\"\n",
    "f\"#SBATCH --output={code_path}{os.sep}logs_{current}{os.sep}output_%j.out\\n\"\n",
    "f\"module load python/epsic3.10\\n\"\n",
    "f\"mapfile -t paths_array < {note_book_path_file}\\n\"\n",
    "'''\n",
    "echo ${paths_array[$SLURM_ARRAY_TASK_ID]}\n",
    "jupyter nbconvert --to notebook --inplace --ClearMetadataPreprocessor.enabled=True ${paths_array[$SLURM_ARRAY_TASK_ID]}\n",
    "jupyter nbconvert --to notebook --allow-errors --execute ${paths_array[$SLURM_ARRAY_TASK_ID]}\n",
    "\n",
    "'''\n",
    "           )\n",
    "        \n",
    "sshProcess = subprocess.Popen(['ssh',\n",
    "                               '-tt',\n",
    "                               'wilson'],\n",
    "                               stdin=subprocess.PIPE, \n",
    "                               stdout = subprocess.PIPE,\n",
    "                               universal_newlines=True,\n",
    "                               bufsize=0)\n",
    "sshProcess.stdin.write(\"ls .\\n\")\n",
    "sshProcess.stdin.write(\"echo END\\n\")\n",
    "sshProcess.stdin.write(f\"sbatch {bash_script_path}\\n\")\n",
    "sshProcess.stdin.write(\"uptime\\n\")\n",
    "sshProcess.stdin.write(\"logout\\n\")\n",
    "sshProcess.stdin.close()\n",
    "\n",
    "\n",
    "for line in sshProcess.stdout:\n",
    "    if line == \"END\\n\":\n",
    "        break\n",
    "    print(line,end=\"\")\n",
    "\n",
    "#to catch the lines up to logout\n",
    "for line in  sshProcess.stdout: \n",
    "    print(line,end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.10-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
