{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5d6e0-4b52-4292-ab8e-fca0e2e5c26e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import h5py\n",
    "import hyperspy.api as hs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33350b69-5f2f-4fc1-9a71-33518c6a7bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_path = '/~/apply_elliptical_correction_polardatacube.py'\n",
    "\n",
    "BEAMLINE = 'e02'\n",
    "YEAR = '2025'\n",
    "VISIT = 'mgXXXXX-X'\n",
    "sub = 'subfolder_name'\n",
    "au_calib_name = 'au_xgrating'\n",
    "base_dir = f'/dls/{BEAMLINE}/data/{YEAR}/{VISIT}/processing/Merlin'\n",
    "au_calib_dir = f'/dls/{BEAMLINE}/data/{YEAR}/{VISIT}/processing/Merlin/{au_calib_name}/' # The whole path can be manually specified\n",
    "\n",
    "# (optional) Angle between the real space dimensions and the reciprocal space dimensions\n",
    "R_Q_ROTATION = '0' \n",
    "\n",
    "also_rpl = 'False' # if 'True', the results will also be saved in '.rpl' format\n",
    "\n",
    "mask_path = '' # if you would like to apply a certain mask to the diffraction patterns\n",
    "\n",
    "fast_origin = True # if not 'True', the process includes the Bragg peak finding (the centre positions could be more accurate, but it needs more time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ca557-bae7-479f-bfcb-d23c42a88ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_adrs = glob.glob(base_dir+'/'+sub+'/*/*/*_data.hdf5', recursive=True)\n",
    "if file_adrs == []:\n",
    "    file_adrs = glob.glob(base_dir+'/'+sub+'/*/*_data.hdf5', recursive=True)\n",
    "    if file_adrs == []:\n",
    "        file_adrs = glob.glob(base_dir+'/'+sub+'/*_data.hdf5', recursive=True)\n",
    "        if file_adrs == []:\n",
    "            print(\"Please make sure that the base directory and subfolder name are correct.\")\n",
    "            \n",
    "print(len(file_adrs))\n",
    "print(*file_adrs, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591fc82-a7f0-4a54-880b-278f9a52935d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_labels = []\n",
    "for adr in file_adrs:\n",
    "    datetime = adr.split('/')[-2]\n",
    "    if os.path.exists(os.path.dirname(adr) + \"/\" + datetime + \"_azimuthal_data_centre.png\"):\n",
    "        continue\n",
    "    else:\n",
    "        data_labels.append(sub+'/'+adr.split('/')[-2])\n",
    "\n",
    "print(len(data_labels))\n",
    "print(*data_labels, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a66055-70be-4154-ac3c-c53a35568a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_path = base_dir + '/' + sub + '/cluster_logs'\n",
    "if not os.path.exists(code_path):\n",
    "    os.mkdir(code_path)\n",
    "    \n",
    "info_path = os.path.join(code_path, 'transformation_info.txt')\n",
    "\n",
    "with open (info_path, 'w') as f:\n",
    "    f.write(\n",
    "        f\"BEAMLINE = {BEAMLINE}\\n\"\n",
    "        f\"YEAR = {YEAR}\\n\"\n",
    "        f\"VISIT = {VISIT}\\n\"\n",
    "        f\"sub = {sub}\\n\"\n",
    "        f\"data_labels = {data_labels}\\n\"\n",
    "        f\"au_calib_dir = {au_calib_dir}\\n\"\n",
    "        f\"R_Q_ROTATION = {R_Q_ROTATION}\\n\"\n",
    "        f\"also_rpl = {also_rpl}\\n\"\n",
    "        f\"mask_path = {mask_path}\\n\"\n",
    "        f\"fast_origin = {fast_origin}\\n\"\n",
    "            )\n",
    "\n",
    "concurrent_jobs = 10 # number of slurm jobs running concurrently\n",
    "bash_script_path = os.path.join(code_path, 'cluster_submit.sh')\n",
    "with open(bash_script_path, 'w') as f:\n",
    "    f.write(\"#!/usr/bin/env bash\\n\")\n",
    "    f.write(\"#SBATCH --partition=cs04r\\n\")\n",
    "    f.write(\"#SBATCH --job-name=rad_trans\\n\")\n",
    "    f.write(\"#SBATCH --nodes=1\\n\")\n",
    "    f.write(\"#SBATCH --ntasks-per-node=4\\n\")\n",
    "    f.write(\"#SBATCH --cpus-per-task=1\\n\")\n",
    "    f.write(\"#SBATCH --time=5:00:00\\n\")\n",
    "    f.write(\"#SBATCH --mem=128G\\n\")\n",
    "    f.write(\"#SBATCH --output=%s/%%j.out\\n\"%code_path)\n",
    "    f.write(\"#SBATCH --error=%s/%%j.error\\n\\n\"%code_path)\n",
    "    f.write(f\"#SBATCH --array=0-{len(data_labels)-1}%{concurrent_jobs}\\n\")\n",
    "    \n",
    "    f.write(\"module load python/epsic3.10\\n\")\n",
    "    f.write(f'python {script_path} {info_path} $SLURM_ARRAY_TASK_ID\\n')\n",
    "\n",
    "sshProcess = subprocess.Popen(['ssh',\n",
    "                               '-tt',\n",
    "                               'wilson'],\n",
    "                               stdin=subprocess.PIPE, \n",
    "                               stdout = subprocess.PIPE,\n",
    "                               universal_newlines=True,\n",
    "                               bufsize=0)\n",
    "sshProcess.stdin.write(\"echo END\\n\")\n",
    "sshProcess.stdin.write(\"sbatch \"+bash_script_path+\"\\n\")\n",
    "sshProcess.stdin.write(\"uptime\\n\")\n",
    "sshProcess.stdin.write(\"logout\\n\")\n",
    "sshProcess.stdin.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.10-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
