{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e411c9-315c-4f9f-b844-615e03f6cbe3",
   "metadata": {},
   "source": [
    "# Atomic structure analysis with radial (azimuthal) average & variance profiles\n",
    "### Jinseok Ryu (jinseok.ryu@diamond.ac.uk)\n",
    "Only compatible with the ePSIC data processig workflow  \n",
    "Recommended to run this notebook using Python 3.10 EPSIC kernel on the jupyterhub of Diamond Light Source  \n",
    "Otherwise, it is highly probable that it will not work properly  \n",
    "[Required Python packages]  \n",
    "scipy, numpy, matplotlib, py4DSTEM, hyperspy, drca (optional for NMF, https://github.com/jinseuk56/drca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87293612-4029-443a-9b6e-78440ecb6355",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/dls/science/groups/e02/Ryu/RYU_at_ePSIC/massive_radial_analysis')\n",
    "\n",
    "from radial_profile_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ec9ec-25b0-45c2-a7c0-0a50c0d550ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "base_dir = ''\n",
    "subfolders = [''] # subfolder names you want to load and compare, e.g., ['sub1', 'sub2']\n",
    "final_dir = None # (optional) folder name where the data is stored in\n",
    "\n",
    "profile_length = 360 # limit the profile size\n",
    "num_load = 25 # limit the number of data for every subfolder (select files randomly)\n",
    "\n",
    "include_key = ['', ''] # keyword (datetime) for screening (to only include the specified data)\n",
    "exclude_key = [] # keyword (datetime) for screening (to exclude poor quality data)\n",
    "\n",
    "run_analysis = radial_profile_analysis(base_dir, subfolders, \n",
    "                                       profile_length, num_load, final_dir,\n",
    "                                       include_key, exclude_key,\n",
    "                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72183487-1c7b-44ff-8920-4886d77ac379",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Transformation quality check (center beam alignment)\n",
    "# If there are any data of poor quality, you can exclude them in the cell above (using 'exclude_key')\n",
    "# crop=[top, bottom, left, right] -> img[top:bottom, left:right] (optional)\n",
    "run_analysis.center_beam_alignment_check(crop=[0, -1, 0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d093ad-0478-4acb-a7f4-8a6c7e25340f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Intensity integration image (BF + DF)\n",
    "run_analysis.intensity_integration_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9279f2-7658-4e1e-ae3b-1b0976e2ed7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To simulate diffraction patterns (XRD) from prismatic structure file(s) (optional)\n",
    "str_path = [] # structure paths to compare, e.g., ['path1', 'path2']\n",
    "\n",
    "# Specify the scattering vector range -> also used in NMF decomposition and plotting\n",
    "from_unit = 0.2 # unit: 1/angstrom, it must be equal to or greater than zero\n",
    "to_unit = 0.8 # unit: 1/angstrom, it must be smaller than the maximum scattering vector\n",
    "run_analysis.basic_setup(str_path, from_unit, to_unit, broadening=0.01, fill_width=0.005) # broadening -> used to simulate diffraction patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c6e24-2355-49c4-877d-25b126fc500d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Sum of radial variance and average profiles\n",
    "# profile_type: \"mean\" or \"variance\"\n",
    "# str_name=[\"structure_name_1\", \"structure_name_2\"]\n",
    "# The structure names are stored in run_analysis.int_sf.keys()\n",
    "run_analysis.sum_radial_profile(str_name=[], profile_type=\"variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a66142-8e79-4cf2-b746-59a721da37f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional process\n",
    "# NMF - to optimize the number of loading vectors\n",
    "# rescale_SI=True -> divide each 3D data by its maximum value\n",
    "# max_normalize=True -> divide every profile by its maximum value\n",
    "# rescale_0_to_1=True -> rescale every profile from 0 to 1\n",
    "# Please refer to Scikit-learn, 'nmf' or 'https://github.com/jinseuk56/drca'\n",
    "# profile_type: \"mean\" or \"variance\"\n",
    "# verbose=True -> it will show the loading vectors and their corresponding coefficient maps\n",
    "# coeff_map_type: \"relative\" or \"absolute\"\n",
    "# coeff_map_type=\"absolute\" -> the colormap range of all the coefficient maps will be determined from the maximum coefficient to the minimum coefficient\n",
    "\n",
    "error_list = []\n",
    "comp_list = []\n",
    "num_comp_list = np.arange(2, 20, 2)\n",
    "for num_comp in num_comp_list:\n",
    "    run_analysis.NMF_decompose(num_comp, profile_type=\"variance\", \n",
    "                               rescale_SI=True, max_normalize=False, rescale_0to1=False, \n",
    "                               verbose=False, coeff_map_type=\"relative\")\n",
    "    error_list.append(run_analysis.run_SI.DR.reconstruction_err_)\n",
    "    comp_list.append(run_analysis.run_SI.DR.components_)\n",
    "\n",
    "# plot the errors between the original dataset and the reconstructed dataset\n",
    "# according to the number of loading vectors\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(num_comp_list, error_list, 'k-')\n",
    "ax.plot(num_comp_list, error_list, 'r*')\n",
    "ax.set_xlabel(\"Number of loading vectors\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot the loading vectors for each case\n",
    "# for i, n_comp in enumerate(num_comp_list):\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "#     for j, comp in enumerate(comp_list[i]):\n",
    "#         ax.plot(comp+j*1.0)\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdda5c-7a08-4a3b-9a6f-f8c171e0f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# NMF - to optimize the number of loading vectors\n",
    "# rescale_SI=True -> divide each 3D data by its maximum value\n",
    "# max_normalize=True -> divide every profile by its maximum value\n",
    "# rescale_0_to_1=True -> rescale every profile from 0 to 1\n",
    "# Please refer to Scikit-learn, 'nmf' or 'https://github.com/jinseuk56/drca'\n",
    "# profile_type: \"mean\" or \"variance\"\n",
    "# verbose=True -> it will show the loading vectors and their corresponding coefficient maps\n",
    "# coeff_map_type: \"relative\" or \"absolute\"\n",
    "# 'relative' -> color scale for each 3D data, 'absolute'-> color scale for all 3D data\n",
    "\n",
    "num_comp = 6\n",
    "run_analysis.NMF_decompose(num_comp, profile_type=\"variance\", rescale_SI=True, \n",
    "                           max_normalize=False, rescale_0to1=False, \n",
    "                           verbose=True, coeff_map_type=\"relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca6fe1-9392-4f3d-9cdd-027fd0e7bb44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# NMF - loading vectors and their coefficient maps\n",
    "# If the number of loading vectors exceeds the number of the preset colormaps (currently five),\n",
    "# it will show the coefficient maps for only 5 loading vectors\n",
    "# lv_show [loading vector number list] -> you can choose which coefficient map to show\n",
    "# The colormap list can be accessed run_analysis.cm_rep -> new colormaps can be added\n",
    "run_analysis.NMF_result(lv_show=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326b14d-1f4f-4179-8b7a-84f9ca92eac0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# NMF - show the pixels with high coefficients for each loading vector and the averaged profiles for those pixels\n",
    "# str_name=[\"structure_name_1\", \"structure_name_2\"]\n",
    "# percentile_threshold -> if 90, only the pixels with the 10% highest coefficients remain\n",
    "by_nmf_lv = run_analysis.NMF_comparison(str_name=[], percentile_threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79113674-4cf3-4c36-ac78-9c93adc0b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "run_analysis.NMF_summary_save(save=False, also_tiff=False, also_dp=False, \n",
    "                              log_scale_dp=True, fill_width=0.005, \n",
    "                              prominence_lv=0.05, prominence_profile=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29d42d-8c10-4f52-a398-862b2f50c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mean profiles of the pixels with high coefficients loading vector by loading vector\n",
    "# import hyperspy.api as hs\n",
    "# by_nmf_lv = np.asarray(by_nmf_lv)\n",
    "# print(by_nmf_lv.shape)\n",
    "# by_nmf_lv = hs.signals.Signal1D(by_nmf_lv)\n",
    "# by_nmf_lv.axes_manager[0].unit = \"loading vector\"\n",
    "# by_nmf_lv.axes_manager[1].scale = run_analysis.pixel_size_inv_Ang\n",
    "# by_nmf_lv.axes_manager[1].unit = \"1/Å\"\n",
    "# by_nmf_lv.save(base_dir+'/mean_profiles_by_loading_vector.hspy', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0b90e-be8d-4ba9-8382-57a8679bc3e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Peak detection\n",
    "# Please refer to SciPy 'find_peaks' for details\n",
    "# scattering vector range -> [peak_position-half_width, peak_position+half_width]\n",
    "half_width = 0.005\n",
    "run_analysis.scattering_range_of_interest(fill_width=half_width,\n",
    "                                         profile_type=\"variance\",\n",
    "                                         prominence=0.01,\n",
    "                                         height=None,\n",
    "                                         width=None,\n",
    "                                         distance=None,\n",
    "                                         threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b42ec-3308-4c46-befc-4cceeba6bb4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variance maps for the specified scattering vector range\n",
    "# Average and standard deviation of variances for the specified scattering vector range\n",
    "# Threshold maps - the pixels with high variances will be 1, otherwise 0\n",
    "### abs_threshold - > absolute threshold value\n",
    "### percentile_threshold -> if 90, only the pixels with the 10% highest variances remain\n",
    "\n",
    "# This will show the results for each peak detected in the cell above\n",
    "# The loop is not necessary\n",
    "sum_radial_list = []\n",
    "for i, peak in enumerate(run_analysis.peak_sub[run_analysis.subfolders[0]]):\n",
    "    peak_selected = peak\n",
    "    print(run_analysis.subfolders[0], \", peak No. %d - range: %.3f ~ %.3f\"%(i+1, peak-half_width, peak+half_width))\n",
    "    run_analysis.variance_map(sv_range=[peak_selected-half_width, peak_selected+half_width])\n",
    "    tmp_sum_radial = run_analysis.high_variance_map(percentile_threshold=90)\n",
    "    print(\"threshold value to determine the high variances: %.3f\"%run_analysis.abs_threshold)\n",
    "    sum_radial_list.append(tmp_sum_radial)\n",
    "\n",
    "    # optional - if you want to see the mean 2D diffraction patterns for individual data\n",
    "    # It will take a long time due to loading each 4D data\n",
    "    # run_analysis.summary_save(save=False, \n",
    "    #                           also_dp=True,\n",
    "    #                           log_scale_dp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4431c6-2209-48c8-922f-f3704626dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mean profiles of the pixels with high variances peak by peak\n",
    "# import hyperspy.api as hs\n",
    "# sum_radial_list = np.asarray(sum_radial_list)\n",
    "# print(sum_radial_list.shape)\n",
    "# sum_radial_list = hs.signals.Signal1D(sum_radial_list)\n",
    "# sum_radial_list.axes_manager[0].unit = \"peak\"\n",
    "# sum_radial_list.axes_manager[1].scale = run_analysis.pixel_size_inv_Ang\n",
    "# sum_radial_list.axes_manager[1].unit = \"1/Å\"\n",
    "# sum_radial_list.save(base_dir+'/mean_profiles_by_peak.hspy', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371bd98-17c5-49d2-ae08-dd4bc4b24703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the mean of radial profiles\n",
    "# run_analysis.basic_setup(str_path, 0.1, 1.0, broadening=0.01) # specify the scattering vector range\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "# sel_peak_num = np.array([1, 2, 3]) - 1 # select a few peaks of interest\n",
    "sel_peak_num = np.arange(len(run_analysis.peak_sub[run_analysis.subfolders[0]])) # for all the peaks\n",
    "\n",
    "for i in sel_peak_num:\n",
    "    ax.plot(run_analysis.x_axis, \n",
    "               sum_radial_list[i][int(run_analysis.from_/run_analysis.pixel_size_inv_Ang):int(run_analysis.to_/run_analysis.pixel_size_inv_Ang)], \n",
    "               c=run_analysis.color_rep[i], label=\"peak No.%d\"%(i+1))\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Scattering vector (1/Å)\")\n",
    "ax.set_facecolor(\"lightgray\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.10-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
